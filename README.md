# ğŸ¤– RAG Chatbot with Amazon Bedrock

A Retrieval-Augmented Generation (RAG) chatbot built using **Amazon Bedrock**, **Amazon OpenSearch Serverless**, and **Amazon S3**.  
This chatbot can answer questions from your own documents (e.g., HR policies, project knowledge base, or personal files) with accurate, context-aware responses.

---

## ğŸš€ Overview
AI chatbots like ChatGPT are powerful, but they canâ€™t answer questions about your private data out of the box.  
This project uses **RAG (Retrieval-Augmented Generation)** to extend a Large Language Model (LLM) hosted on **Amazon Bedrock**, allowing it to retrieve relevant information from custom documents stored in **S3** and indexed in **OpenSearch**.

**Use case demo:**  
Here, the chatbot is specialized for **HR policies**, letting employees ask questions like:  
- â€œWhat are the vacation policies?â€  
- â€œHow does the performance review process work?â€  
- â€œWhat healthcare benefits are available?â€  

---

## ğŸ› ï¸ Tech Stack
- **Amazon Bedrock** â€“ Large Language Models (LLMs) for response generation  
- **Amazon S3** â€“ Document storage for HR policies / custom knowledge base  
- **Amazon OpenSearch Serverless** â€“ Vector search database for semantic retrieval  
- **Python (Boto3 SDK)** â€“ Backend integration with AWS services  

---

## ğŸ”„ Architecture

```text
User â†’ Chatbot UI â†’ Amazon Bedrock (LLM)
                     â†˜ Retrieval (RAG)
                        â†’ OpenSearch (Vector DB)
                            â†˜ Amazon S3 (Document Store)

